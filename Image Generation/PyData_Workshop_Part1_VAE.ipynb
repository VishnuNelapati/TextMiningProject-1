{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGUe95bHmbEu"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dimtr/PyDataEHV_workshop/blob/master/Image%20Generation/PyData_Workshop_Part1_VAE.ipynb\" target=\"_parent\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "\n",
    "\n",
    "## Variational Autoencoder (VAE) ( proposed in [this article](https://arxiv.org/abs/1312.6114)) \n",
    "<img src=\"Images/VAE_image.PNG\" width=\"700\">\n",
    "\n",
    "### Variational autoencoder using [Keras](https://keras.io/) with tensorflow in the backend and [tensorflow_probability](https://github.com/tensorflow/probability)\n",
    "\n",
    "\n",
    "### [Guiding principles](https://keras.io/#guiding-principles) of Keras:\n",
    "####    *User friendliness: consistent and simple APIs, clear and actionable error messages\n",
    "####    *Modularity:  a model is a graph of stand alone components (neural layers, cost functions, optimizers, activation functions etc)\n",
    "####    *Easy extensibility: new modules are simple to add (as classes and functions)\n",
    "####    *Work with python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnpQFIz7m85v"
   },
   "source": [
    "### Install packages for in colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35510,
     "status": "ok",
     "timestamp": 1574839785786,
     "user": {
      "displayName": "Dimitra Gkorou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAJyMsiKZQcKwzF0kb4FBpLaffBjfgzsOVHawSopA=s64",
      "userId": "09206597593832726771"
     },
     "user_tz": -60
    },
    "id": "W0E6nZRxlvLZ",
    "outputId": "3ba17601-1184-4bcd-c60a-e61424641691"
   },
   "outputs": [],
   "source": [
    "def run_subprocess_command(cmd):\n",
    "    process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "    for line in process.stdout:\n",
    "        print(line.decode().strip())\n",
    "\n",
    "\n",
    "import sys, subprocess\n",
    "\n",
    "colab_requirements = [\n",
    "    #TensorFlow 2.0 (nightly builds)\n",
    "    \"pip install tf-nightly-gpu-2.0-preview==2.0.0.dev20190513\",\n",
    "    #tpf (nightly builds): library for probabilistic reasoning and statistical analysis in TensorFlow\n",
    "    \"pip install tfp-nightly==0.7.0.dev20190508\",\n",
    "]\n",
    "\n",
    "for i in colab_requirements:\n",
    "    run_subprocess_command(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I1izSQFWn4vp"
   },
   "source": [
    "\n",
    "\n",
    "### Load modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38125,
     "status": "ok",
     "timestamp": 1574839789437,
     "user": {
      "displayName": "Dimitra Gkorou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAJyMsiKZQcKwzF0kb4FBpLaffBjfgzsOVHawSopA=s64",
      "userId": "09206597593832726771"
     },
     "user_tz": -60
    },
    "id": "XTQyyY3Cn38J",
    "outputId": "02b16b17-9bdb-42a9-8b0e-586f5409b88e"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "#package for progress bar in python\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import (Input, InputLayer, Dense, Lambda, Layer, \n",
    "                          Add, Multiply)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "ds = tfp.distributions\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ZvlKC7ECw3u"
   },
   "source": [
    "### There are two APIs for defining a model in Keras:\n",
    "#### * [Sequential model API](https://keras.io/models/sequential/) : easy to define a linear stack of layers quickly. (e.g. the output of one layer is the input of the next layer in stack).\n",
    "#### * [Functional model API](https://keras.io/getting-started/functional-api-guide/) :more flexible and allows non-linear NN stack\n",
    "\n",
    "In this workshop, we use the Sequential one because it allows us to quickly define a simple VAE encoder architecture stacking a couple  of convolution layers, flatten them, and connect them with a Dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IE71z2VdsVz2"
   },
   "outputs": [],
   "source": [
    "#notebook aesthetics\n",
    "np.set_printoptions(precision=2,\n",
    "                    edgeitems=3,\n",
    "                    linewidth=80,\n",
    "                    suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eoak35YmrG3x"
   },
   "source": [
    "### Create a fashion-MNIST dataset\n",
    "The Fashion MNIST dataset was created by e-commerce company, Zalando, as a replacement for MNIST Digits. It is a nice dataset to quickly check and prototype algorithms while it is more complex than simple MNIST.\n",
    "\n",
    "The Fashion MNIST dataset is identical to the MNIST dataset in terms of training set size, testing set size, number of class labels, and image dimensions:\n",
    "\n",
    "*   60,000 training example\n",
    "*   10,000 testing examples\n",
    "*   10 classes\n",
    "*   28Ã—28 grayscale images\n",
    "\n",
    "You cna find a complete description of the dataset [here](https://github.com/zalandoresearch/fashion-mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39730,
     "status": "ok",
     "timestamp": 1574839798243,
     "user": {
      "displayName": "Dimitra Gkorou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAJyMsiKZQcKwzF0kb4FBpLaffBjfgzsOVHawSopA=s64",
      "userId": "09206597593832726771"
     },
     "user_tz": -60
    },
    "id": "QVj4n3aosgVF",
    "outputId": "4ff35c33-7b84-4996-919c-234254d2be88"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gKTyOPdPpE44"
   },
   "source": [
    "### Visualize some images using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2356,
     "status": "ok",
     "timestamp": 1574839879243,
     "user": {
      "displayName": "Dimitra Gkorou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAJyMsiKZQcKwzF0kb4FBpLaffBjfgzsOVHawSopA=s64",
      "userId": "09206597593832726771"
     },
     "user_tz": -60
    },
    "id": "FMybBOJEvrH8",
    "outputId": "93ff54c2-26d5-46b3-e68c-ec0bb3b8e249"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "for i in range(0,16): # how many imgs will show on a grid \n",
    "    plt.subplot(4,4, i+1) # open next subplot\n",
    "    plt.imshow(x_train[i], cmap=plt.get_cmap('gray_r'))\n",
    "    plt.title(y_train[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SWS4L9jdpgjo"
   },
   "outputs": [],
   "source": [
    "TRAIN_BUF= x_train.shape[0]\n",
    "BATCH_SIZE=512\n",
    "TEST_BUF=x_test.shape[0]\n",
    "DIMS = (x_train.shape[1],x_train.shape[2],1)\n",
    "N_TRAIN_BATCHES =int(TRAIN_BUF/BATCH_SIZE)\n",
    "N_TEST_BATCHES = int(TEST_BUF/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1E_6TDwUqsgx"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cblsrh7ErL-6"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# split dataset and normalize\n",
    "train_images = x_train.reshape(x_train.shape[0],DIMS[0], DIMS[1], 1).astype(\"float32\") / 255.0\n",
    "test_images = x_test.reshape(x_test.shape[0],DIMS[0], DIMS[1], 1).astype(\"float32\") / 255.0\n",
    "\n",
    "# batch datasets\n",
    "# construct a tf Dataset from make a dataset from a numpy array in memory \n",
    "# and automatically suffle and batch the dataset with the provided batch size\n",
    "# tf.Dataset is an efficient way to pass data to tf \n",
    "train_dataset = (\n",
    "\n",
    "    tf.data.Dataset.from_tensor_slices(train_images)\n",
    "    .shuffle(TRAIN_BUF)\n",
    "    .batch(BATCH_SIZE)\n",
    ")\n",
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(test_images)\n",
    "    .shuffle(TEST_BUF)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reparameterization trick for VAEs \n",
    "\n",
    "To implement encoder and decoder as a neural network, we need to backpropogate through random sampling but backpropogation cannot flow through random node. To overcome this,  VAEs use reparameterization trick: \n",
    "\n",
    "$Z$ is approximated with normally distributed $\\epsilon$:\n",
    "\n",
    "$Z\\sim N(0,\\Sigma) \\Rightarrow z = \\mu + L\\epsilon, \\epsilon\\sim N(0,1),\\Sigma=LL^T$\n",
    "\n",
    "Now, instead of seeing $Z$ as sampled from $Q(z\\m \\phi,x)$, we see $Z$ as a function that takes parameter $(\\epsilon,( \\mu, L))$ and  $\\mu$, $L$ come from the encoder. Therefore during backpropogation, all we need is partial derivatives w.r.t. $\\mu$, $L$ and $\\epsilon$ is irrelevant for taking derivatives.\n",
    "\n",
    "This trick is shown in the Figure below, taken from [source](https://arxiv.org/pdf/1606.05908.pdf) \n",
    "\n",
    "<img align=\"left\" src=\"Images/Reparameterization_trick.PNG\" width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMgu5LbtrOXL"
   },
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "    \"\"\"a basic vae class for tensorflow\n",
    "    Extends: tf.keras.Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(VAE, self).__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "        #encoder \n",
    "        self.enc = tf.keras.Sequential(self.enc)\n",
    "        #decoder\n",
    "        self.dec = tf.keras.Sequential(self.dec)\n",
    "\n",
    "    # getting the mulitvariate normal distribution returned by the VAE encoder\n",
    "    def encode(self, x):\n",
    "        #Splits a tensor into sub tensors mu and sigma\n",
    "        mu, sigma = tf.split(self.enc(x), num_or_size_splits=2, axis=1)\n",
    "        #create and return the multivariate normal distribution on R^k\n",
    "        return ds.MultivariateNormalDiag(loc=mu, scale_diag=sigma)\n",
    "    \n",
    "    # reparameterization trick, sampling from the distribution returned by the encoder\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * 0.5) + mean\n",
    "\n",
    "    #take a data point from the latent space and reconstruct its shape\n",
    "    def reconstruct(self, x):\n",
    "        mu, _ = tf.split(self.enc(x), num_or_size_splits=2, axis=1)\n",
    "        return self.decode(mu)\n",
    "    \n",
    "    #return the decoded values\n",
    "    def decode(self, z):\n",
    "        return self.dec(z)\n",
    "\n",
    "    #compute the loss function of VAE by estimating:\n",
    "    # 1. the image loss is computed using the binary cross entropy formula, which can be interpreted as the minus log likelihood of our data\n",
    "    # 2. the latent loss using the KL divergence formula (for a normal and a standard normal distribution)\n",
    "    # finally, we get the mean of all the image losses\n",
    "    # someone can add weight on the two loss functions and optimize it as hyperparameter \n",
    "    def compute_loss(self, x):\n",
    "\n",
    "        q_z = self.encode(x)\n",
    "        z = q_z.sample()\n",
    "        x_recon = self.decode(z)\n",
    "        p_z = ds.MultivariateNormalDiag(\n",
    "          loc=[0.] * z.shape[-1], scale_diag=[1.] * z.shape[-1]\n",
    "          )\n",
    "        kl_div = ds.kl_divergence(q_z, p_z)\n",
    "        latent_loss = tf.reduce_mean(tf.maximum(kl_div, 0))\n",
    "        recon_loss = tf.reduce_mean(tf.reduce_sum(tf.math.square(x - x_recon), axis=0))\n",
    "\n",
    "        return recon_loss, latent_loss\n",
    "\n",
    "    def compute_gradients(self, x):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.compute_loss(x)\n",
    "        return tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "    @tf.function\n",
    "    def train(self, train_x):\n",
    "        gradients = self.compute_gradients(train_x)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rY43jXIotXsm"
   },
   "source": [
    "### Define the network architecture\n",
    "* Quick Recap: Convolutions for encoder. Images from [source1](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53) and [source2](https://github.com/vdumoulin/conv_arithmetic)\n",
    "\n",
    "<img align=\"left\" src=\"Images/1_GcI7G-JLAQiEoCON7xFbhg.gif\" width=\"250\"  alt=\"with filter\"  hspace=\"200\"/><img align=\"left\" src=\"Images/1_1VJDP6qDY9-ExTuQVEOlVg.gif\" width=\"250\" hspace=\"200\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Deconvolutions (transpose convolutions) for the decoder\n",
    "\n",
    "<img align=\"left\" src=\"Images/f2RiP.gif\" width=\"250\"  alt=\"with filter\"  hspace=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TT76gxqHqn2E"
   },
   "outputs": [],
   "source": [
    "N_Z = 2\n",
    "encoder = [\n",
    "    tf.keras.layers.InputLayer(input_shape=DIMS),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=32, kernel_size=3, strides=(2, 2), activation=\"relu\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=64, kernel_size=3, strides=(2, 2), activation=\"relu\"\n",
    "    ),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=N_Z*2),\n",
    "]\n",
    "\n",
    "decoder = [\n",
    "    tf.keras.layers.Dense(units=7 * 7 * 64, activation=\"relu\"),\n",
    "    tf.keras.layers.Reshape(target_shape=(7, 7, 64)),\n",
    "    tf.keras.layers.Conv2DTranspose(\n",
    "        filters=64, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=\"relu\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2DTranspose(\n",
    "        filters=32, kernel_size=3, strides=(2, 2), padding=\"SAME\", activation=\"relu\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2DTranspose(\n",
    "        filters=1, kernel_size=3, strides=(1, 1), padding=\"SAME\", activation=\"sigmoid\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3U2GBWmLuFtY"
   },
   "source": [
    "###Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88IUELGUuEDh"
   },
   "outputs": [],
   "source": [
    "# the optimizer for the model\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "# train the model\n",
    "model = VAE(\n",
    "    enc = encoder,\n",
    "    dec = decoder,\n",
    "    optimizer = optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1574839902292,
     "user": {
      "displayName": "Dimitra Gkorou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAJyMsiKZQcKwzF0kb4FBpLaffBjfgzsOVHawSopA=s64",
      "userId": "09206597593832726771"
     },
     "user_tz": -60
    },
    "id": "uFcVwiJ2OFhv",
    "outputId": "3f3f09f2-2da4-45b0-d476-da059d1a6749"
   },
   "outputs": [],
   "source": [
    "# see datails of the model\n",
    "model.enc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_OjKcNJvtVg"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GmgqaNTWtanp"
   },
   "outputs": [],
   "source": [
    "# example data from the test set for plotting results \n",
    "example_data = next(iter(test_dataset))\n",
    "\n",
    "\n",
    "def plot_reconstruction(model, example_data, nex=8, zm=2):\n",
    "\n",
    "    example_data_reconstructed = model.reconstruct(example_data)\n",
    "    #and generate images from some random samples\n",
    "    samples = model.decode(tf.random.normal(shape=(BATCH_SIZE, N_Z)))\n",
    "    fig, axs = plt.subplots(ncols=nex, nrows=3, figsize=(zm * nex, zm * 3))\n",
    "    for axi, (dat, lab) in enumerate(\n",
    "        zip(\n",
    "            [example_data, example_data_reconstructed, samples],\n",
    "            [\"data\", \"data recon\", \"samples\"],\n",
    "        )\n",
    "    ):\n",
    "        for ex in range(nex):\n",
    "            axs[axi, ex].matshow(\n",
    "                dat.numpy()[ex].squeeze(), cmap=plt.cm.Greys, vmin=0, vmax=1\n",
    "            )\n",
    "            axs[axi, ex].axes.get_xaxis().set_ticks([])\n",
    "            axs[axi, ex].axes.get_yaxis().set_ticks([])\n",
    "        axs[axi, 0].set_ylabel(lab)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecazHP7svwpW"
   },
   "outputs": [],
   "source": [
    "# a pandas dataframe to save the loss information to\n",
    "losses = pd.DataFrame(columns = ['recon_loss', 'latent_loss'])\n",
    "# a pandas dataframe to save the loss information to\n",
    "#losses = pd.DataFrame(columns = [ 'recon_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMYDr1htLwDv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1192,
     "status": "ok",
     "timestamp": 1574802323511,
     "user": {
      "displayName": "Dimitra Gkorou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAJyMsiKZQcKwzF0kb4FBpLaffBjfgzsOVHawSopA=s64",
      "userId": "09206597593832726771"
     },
     "user_tz": -60
    },
    "id": "SIEH6LgUwn6e",
    "outputId": "77275c22-41bf-4ec0-ce0a-b01adefab6fb"
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    # train\n",
    "    #create the progress bar\n",
    "    for batch, train_x in tqdm(\n",
    "        zip(range(N_TRAIN_BATCHES), train_dataset), total=N_TRAIN_BATCHES\n",
    "    ):\n",
    "        model.train(train_x)\n",
    "    # test on holdout\n",
    "    loss = []\n",
    "    for batch, test_x in tqdm(\n",
    "        zip(range(N_TEST_BATCHES), test_dataset), total=N_TEST_BATCHES\n",
    "    ):\n",
    "        loss.append(model.compute_loss(train_x))\n",
    "    losses.loc[len(losses)] = np.mean(loss, axis=0)\n",
    "    # plot results\n",
    "    display.clear_output()\n",
    "    print(\n",
    "        \"Epoch: {} | recon_loss: {} | latent_loss: {}\".format(\n",
    "            epoch, losses.recon_loss.values[-1] , losses.latent_loss.values[-1]\n",
    "            #\"Epoch: {} | recon_loss: {}\".format(\n",
    "            #epoch, losses.recon_loss.values[-1] #, losses.latent_loss.values[-1]\n",
    "        )\n",
    "    )\n",
    "    plot_reconstruction(model, example_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5wcsIw7iZrCO"
   },
   "source": [
    "### Visualize the latent representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JlwtQhdpGEzv"
   },
   "outputs": [],
   "source": [
    "q_z = model.encode(train_images)\n",
    "latent_z = q_z.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5553,
     "status": "ok",
     "timestamp": 1574800525558,
     "user": {
      "displayName": "Dimitra Gkorou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAJyMsiKZQcKwzF0kb4FBpLaffBjfgzsOVHawSopA=s64",
      "userId": "09206597593832726771"
     },
     "user_tz": -60
    },
    "id": "p2O6Np_vGiMV",
    "outputId": "4041746e-072a-4d86-a49b-cb05b1f3f21b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8), dpi=80)\n",
    "\n",
    "colormap = ListedColormap(sns.color_palette(sns.hls_palette(10, l=.45 , s=.8)).as_hex())\n",
    "plt.scatter(latent_z[:, 0], latent_z[:, 1], c=y_train, cmap=colormap)\n",
    "\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_yticklabels(['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "                                                     'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])\n",
    "\n",
    "plt.title('Latent space')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the same dataset with UMAP - a k-nn based dimensionality reduction technique.\n",
    "Umap does not supporting inverse transformation and not data generation but it is optimized for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 82341,
     "status": "ok",
     "timestamp": 1574797946014,
     "user": {
      "displayName": "Dimitra Gkorou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAJyMsiKZQcKwzF0kb4FBpLaffBjfgzsOVHawSopA=s64",
      "userId": "09206597593832726771"
     },
     "user_tz": -60
    },
    "id": "wkmxu4kUJ4VC",
    "outputId": "99223ec9-f660-442e-f5ac-36243c5c6211"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.set(context=\"paper\", style=\"white\")\n",
    "\n",
    "\n",
    "reducer = umap.UMAP(random_state=42,n_neighbors=5)\n",
    "embedding = reducer.fit_transform(x_train.reshape(x_train.shape[0],28*28))\n",
    "\n",
    "plt.figure(figsize=(15, 8), dpi=80)\n",
    "\n",
    "colormap = ListedColormap(sns.color_palette(sns.hls_palette(10, l=.45 , s=.8)).as_hex())\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=y_train, cmap=colormap)\n",
    "\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_yticklabels(['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "                                                     'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])\n",
    "\n",
    "plt.title('Latent space')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NoKFhV9PAJ4P"
   },
   "source": [
    "### Generate and morphe images \n",
    "show grid in 2D latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1495,
     "status": "ok",
     "timestamp": 1574798055977,
     "user": {
      "displayName": "Dimitra Gkorou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAJyMsiKZQcKwzF0kb4FBpLaffBjfgzsOVHawSopA=s64",
      "userId": "09206597593832726771"
     },
     "user_tz": -60
    },
    "id": "GtQTwzuhAJS_",
    "outputId": "fce9e10f-3be1-4b47-ecd6-fe6fb8f9abfd"
   },
   "outputs": [],
   "source": [
    "# sample from grid\n",
    "nx = ny =10\n",
    "meshgrid = np.meshgrid(np.linspace(-3, 3, nx), np.linspace(-3, 3, ny))\n",
    "meshgrid = np.array(meshgrid).reshape(2, nx*ny).T\n",
    "x_grid = model.decode(meshgrid)\n",
    "x_grid = x_grid.numpy().reshape(nx, ny, 28,28, 1)\n",
    "# fill canvas\n",
    "canvas = np.zeros((nx*28, ny*28))\n",
    "for xi in range(nx):\n",
    "    for yi in range(ny):\n",
    "        canvas[xi*28:xi*28+28, yi*28:yi*28+28] = x_grid[xi, yi,:,:,:].squeeze()\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.matshow(canvas, cmap=plt.cm.Greys)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OgELdyTOwqcW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Mynotebook_workshop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
